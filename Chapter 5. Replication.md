# Глава 5. Репликация.

Репликация может служить нескольким целям:
- Высокая доступность. Сохранение работоспособности системы в целом даже в случае 
отказа одной из машин (или нескольких машин, или даже целого ЦОДа).
- Работа в офлайн-режиме. Возможность продолжения работы приложения в случае 
прерывания соединения с сетью.
- Задержка. Данные размещаются географически близко к пользователям, 
чтобы те могли работать с ними быстрее.
- Масштабирование. Возможность обрабатывать большие объемы операций чтения, 
чем способна обработать одна машина, с помощью выполнения операций чтения на репликах.

## Ведущие и ведомые узлы.
Все операции записи производятся через leader-реплику (ведущий узел).
Когда ведущий узел записывает в своё локальное хранилище новые данные,
followers (ведомые узлы) обновляют свою локальную копию данных,
применяя все изменения в то же порядке, в каком их принимает ведущий узел.


### Syncronous replication.  
Синхронная репликация гарантирует, что копия данных ведомого узла полностью соответствует 
данным ведущего (strong consistency, строгая согласованность). Но если хотя бы один из ведомых узлов недоступен, запись новых данных и в ведущий, и во все остальные ведомые узлы блокируется.

### Semi-synchronous replication.
Один из ведомых узлов может копировать данные синхронно, а остальные - асинхронно. 
В этом случае вероятность блокировки (при недоступном синхронном ведомом узле) в целом снижается, при этом гарантируется, что данные находятся в строгой согласованности по меньше мере на двух репликах (на ведущем и синхронном ведомом узлах). Если синхронный ведомый узел становится недоступным, его роль начинает выполнять одинн из асинхронных.

### Asynchronous replication.
Все ведомые узлы могут быть недоступны, но ведущий продолжит принимать запросы на операции записи. 
Если ведущий узел "падает", часть данных теряется.


### Добавление нового ведомого узла.
1. Сделать согласованный снимок данных с ведущего узла. При этом зафиксировать конкретную позицию 
в журнале репликации, соответствующую этому снимку.
2. Скопировать данные из этого снимка на новый ведомый узел.
3. Новый ведомый узел запрашивает и копирует данные с ведущего узла начиная с зафиксированной позиции.
4. Ведомый узел привёл данные в соответствие ведущему (caught up). Далее он копирует данные 
при необходимости в обычном режиме.


### Перебои в работе узлов.
При отказе и перезапуске ведомого узла он просто запрашивает данные с ведущего начиная с последней 
обработанной транзакции согласно своему журналу.

### Восстановление при отказе ведущего узла состоит из следующих шагов:
1. Определить, что ведущий узел отказал (обычно с помощью регулярного взаимного опрашивания узлов).
2. Выбрать новый ведущий узел (обычно выбирается ведомый узел с наиболее свежей копией данных). 
При выборе может возникнуть проблема консенсуса (consensus problem).
3. Перенастроить систему на работу с новым ведущим узлом: все узлы считают выбранным узел ведущим, 
в том числе перезапущенный после отказа экс-ведущий узел.

### Проблемы, которые могут возникнуть:
- При асинхронной репликации безвозвратно пропадает часть данных, записанных ведущим узлом перед отказом.
- Split brain - несколько узлов считают себя ведущими. Может привести к несогласованности данных. 
Обычно решается механизмом отключения при обнаружении нескольких ведущих узлов.
- Проблема определения интервала времени (timeout), после которого можно считать ведущий узел отказавшим.


### Реализации журнала репликации.
- Statement-based (опасность наличия в запросах недетерменированных функций и авто-инкрементирующих столбцов)
- Write-ahead log (недостаток в слишком детальном описании данных, завязанном на механизме хранения)
- Logical (row-based) log
- Trigger-based. Изменения записываются в отдельную таблицу, откуда их затем читает внешний процесс (и реплицирует).


## Проблемы задержки реплицирования.
### Reading your own writes.
Пользователь может сделать запись, но не увидеть её, произведя чтение с ведомого, который ещё не привёл данные 
в соответствие с ведущий узлом.
Решения:
- Читать то, чтопользователь мог изменить, с ведущего узла, а всё остальное - с ведомых.
- Запоминать время последнего обновления и, например, в течение 1 минуты после этого момента читать данные лишь с ведущего узла.
- Следить за задержкой реплицирования и читать данные лишь с тех ведомых узлов, у которых она больше допустимой.
- Возложить на клиента запоминание времени последнего обновления (или какой-либо логической метки, например, значения счётчика), 
тогда при чтении с ведомого узла он сможет определять, актуальны ли данные у реплики, к которой он обратился 
(и далее решать, обратиться ли к другой реплике или подождать и повторить запрос).

Чтение может производиться пользователем с разных устройств, при этом чтение должно давать пользователю одинаковые результаты.

### Monotonic reads.
Чтение с разных реплик не должно давать противоречивые результаты. После того как пользователь увидел данные по состоянию на 
какой-либо момент времени, он не должен позднее увидеть те же данные по состоянию на более ранний момент времени.
Решение: привязывать пользователя к чтению всегда из одной конкретной реплики, например, выбираемой на основе хэша идентификатора пользователя. 
Но в случае сбоя этой реплики чтение будет произведеной из другой.

### Consistent Prefix Reads.
Пользователи должны видеть данные в состоянии, не нарушающем причинно-следственных связей: например, видеть вопрос и ответ на него в правильном порядке.


## Репликация с несколькими ведущими узлами (multileader).
Несколько узлов являются ведущими, принимая запросы на чтение.
Примеры использования:
- Несколько ЦОДов.
- Оффлайн-клиенты.
- Совместное редактирование.

### Обработка конфликтов записи.
При реплицировании с несколькими ведущими узлами могут возникнуть конфликты из-за операций, произведённых параллельно на разных узлах.

Стратегии борьбы:
- Избегать появления конфликтов. Делать операции записи над одними данными строго через один ведущий узел.
- Решать конфликт сходимостью (при обнаружении конфликта реплики сходятся к решению, какое итоговое значение оставить). Примеры решения:
  -- Присвоить идентификатор каждой операции записи. Сохранять результат операции с наивысшим идентификатором.
  -- Присвоить идентификатор каждой реплике. Сохранять результат операции на реплике с наивысшим идентификатором.
  -- Производить слияние данных (объединение двух значений в одно, например, посредством конкатенации).
  -- Делать запись о конфликте, чтобы впоследствии программно решить его. 

Решать конфликт можно, обнаруживая конфликт при записи или при чтении. 


## Репликация без ведущего узла.
Любой узел принимает запросы на запись. Чтение производится с нескольких узлов, результат чтения помечается меткой (временн*о*й или номером версии).
Если происходит сбой узла, после возобновления его работы привести данные на этом узле в целостное состояние можно двумя путями:
- При чтении. Клиент получает результаты чтения с нескольких узлов с разными метками. По значениям меток клиент понимает, что один из узлов отстаёт, и
производит запись актуальной версии данных на этот узел.
- Антриэнтропия. Фоновый процесс следит за разницей в состоянии данных и производит их копирование с узла на узел.

### Кворумы на чтение и запись.
Если есть *n* реплик и при операции записи нужно получить подтверждение от *w* узлов, то **для получения целостных данных** запрос на чтение
нужно отправить по меньшей мере такому количеству *r* узлов, что *w + r > n*.

Можно применять кворумы вопреки этому правилу, ожидая подтверждение об успешной записи от меньшего количества узлов и делая запросы
на чтение меньшему количеству узлов. В этом случае снижается задержка (latency) и повышается доступность (если несколько узлов недоступны,
при обращении к меньшему количеству узлов выше шанс всё же продолжить запись и чтение), но повышается шанс получить не свежие данные.

Правило *w + r > n* также не даёт гарантий получения всегда целостных данных, так как могут произойти граничные случаи:
- использование нестрогих кворумов
- при параллельной записи нельзя сделать вывод, какая из операций записи была первой. В этом случае решением будет слияние двух записей. 
Если "победитель" выбирается на основе метки времени, результат одной из операций записи может быть потерян из-за рассинхронизации часов.
- если операция записи выполняется параллельно с чтением, её результат может оказаться лишь на нескольких  узлах. В этом случае невозможно
определить, вернула ли операция чтения старое значение или же новое.
- если операция записи завершилась успешно на одних узлах, но неуспешно на других, она не всегда откатывается на первых. Последующая операция чтения
может возвращать как старое, так и новое значения.
- если происходит отказ узла с новым значением, данные восстанавливаются с узла со старым значением. В этом случае число *w* уменьшается, и кворум
*w + r > n* может перестать соблюдаться.
- проблемы линеаризации.

### Нестрогие кворумы.
Сетевые сбои могут могут прервать связь клиента с большим количеством узлов. В этом случае имеет место решение с нестрогим кворумом:
для операций записи и чтения по-прежнему необходимо *w* и *r* подтверждений успешного выполнения, но при этом учитываются узлы, не входящие в число 
намеченных для значения n «родных» узлов. После исправления сбоя сети все операции записи, временно отправленные в какой-либо узел вместо недоступного, 
отправляются в соответствующие «родные» узлы. Это называется направленной передачей (hinted handoff).
